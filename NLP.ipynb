{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f60c0c9-b8cf-4b35-894d-97bd21fd54ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da288b93-fd5c-447d-9095-5576c6e99380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf20962f-1d7d-4e5f-a553-d55c40add27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c58a5b08-b801-4b0c-9d9b-c76dbd012c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49cb931c-d0b7-4e9d-8ab0-38c5498b5836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df['clean_text'] = df['review'].apply(lambda x:re.sub(\"<.*?>\",\"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "438e8b7c-cdbd-40f6-9e96-39409545e599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['clean_text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bcdb4bf-b856-4907-809d-1ce0b9f6290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['clean_text'].apply(lambda x:re.sub(r'[^\\w\\s]', \"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec21543d-cd69-4b65-b983-cf822e82814e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production The filming technique is very unassuming very oldtimeBBC fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece The actors are extremely well chosen Michael Sheen not only has got all the polari but he has all the voices down pat too You can truly see the seamless editing guided by the references to Williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece A masterful production about one of the great masters of comedy and his life The realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears It plays on our knowledge and our senses particularly with the scenes concerning Orton and Halliwell and the sets particularly of their flat with Halliwells murals decorating every surface are terribly well done'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8a0c09d-e72d-4896-b641-096a49e6c261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['clean_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a6f6433-c930-48a3-bfa1-f45de036afe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonderful little production the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "922d7223-f842-4556-804a-910fcf3014f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58d6c545-3bca-4afa-ae48-8b2ea55d7572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdd16394-c794-474e-891f-52c1f5924099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenize_text'] = df['clean_text'].apply(lambda x:word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8abc1253-016b-4bc0-84a9-0e61c1261c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'wonderful',\n",
       " 'little',\n",
       " 'production',\n",
       " 'the',\n",
       " 'filming',\n",
       " 'technique',\n",
       " 'is',\n",
       " 'very',\n",
       " 'unassuming',\n",
       " 'very',\n",
       " 'oldtimebbc',\n",
       " 'fashion',\n",
       " 'and',\n",
       " 'gives',\n",
       " 'a',\n",
       " 'comforting',\n",
       " 'and',\n",
       " 'sometimes',\n",
       " 'discomforting',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'realism',\n",
       " 'to',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'piece',\n",
       " 'the',\n",
       " 'actors',\n",
       " 'are',\n",
       " 'extremely',\n",
       " 'well',\n",
       " 'chosen',\n",
       " 'michael',\n",
       " 'sheen',\n",
       " 'not',\n",
       " 'only',\n",
       " 'has',\n",
       " 'got',\n",
       " 'all',\n",
       " 'the',\n",
       " 'polari',\n",
       " 'but',\n",
       " 'he',\n",
       " 'has',\n",
       " 'all',\n",
       " 'the',\n",
       " 'voices',\n",
       " 'down',\n",
       " 'pat',\n",
       " 'too',\n",
       " 'you',\n",
       " 'can',\n",
       " 'truly',\n",
       " 'see',\n",
       " 'the',\n",
       " 'seamless',\n",
       " 'editing',\n",
       " 'guided',\n",
       " 'by',\n",
       " 'the',\n",
       " 'references',\n",
       " 'to',\n",
       " 'williams',\n",
       " 'diary',\n",
       " 'entries',\n",
       " 'not',\n",
       " 'only',\n",
       " 'is',\n",
       " 'it',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'the',\n",
       " 'watching',\n",
       " 'but',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'terrificly',\n",
       " 'written',\n",
       " 'and',\n",
       " 'performed',\n",
       " 'piece',\n",
       " 'a',\n",
       " 'masterful',\n",
       " 'production',\n",
       " 'about',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'great',\n",
       " 'masters',\n",
       " 'of',\n",
       " 'comedy',\n",
       " 'and',\n",
       " 'his',\n",
       " 'life',\n",
       " 'the',\n",
       " 'realism',\n",
       " 'really',\n",
       " 'comes',\n",
       " 'home',\n",
       " 'with',\n",
       " 'the',\n",
       " 'little',\n",
       " 'things',\n",
       " 'the',\n",
       " 'fantasy',\n",
       " 'of',\n",
       " 'the',\n",
       " 'guard',\n",
       " 'which',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'use',\n",
       " 'the',\n",
       " 'traditional',\n",
       " 'dream',\n",
       " 'techniques',\n",
       " 'remains',\n",
       " 'solid',\n",
       " 'then',\n",
       " 'disappears',\n",
       " 'it',\n",
       " 'plays',\n",
       " 'on',\n",
       " 'our',\n",
       " 'knowledge',\n",
       " 'and',\n",
       " 'our',\n",
       " 'senses',\n",
       " 'particularly',\n",
       " 'with',\n",
       " 'the',\n",
       " 'scenes',\n",
       " 'concerning',\n",
       " 'orton',\n",
       " 'and',\n",
       " 'halliwell',\n",
       " 'and',\n",
       " 'the',\n",
       " 'sets',\n",
       " 'particularly',\n",
       " 'of',\n",
       " 'their',\n",
       " 'flat',\n",
       " 'with',\n",
       " 'halliwells',\n",
       " 'murals',\n",
       " 'decorating',\n",
       " 'every',\n",
       " 'surface',\n",
       " 'are',\n",
       " 'terribly',\n",
       " 'well',\n",
       " 'done']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenize_text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2044765e-c2a6-4920-b2c5-333f2a042e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DAIDA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3088ef45-e95f-424d-9d56-a18a13efb75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c19229b-b818-4d42-bb5b-48699f6b292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4f37d4e-e1d3-416a-802f-970772bf0f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c662e600-863a-4a37-9aa6-8a847591a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filtered_text'] = df['tokenize_text'].apply(lambda x:[word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dd8fede-bbee-4fae-849b-016e3f8cf6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['filtered_text'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db25a899-3dc2-4fb9-a498-3ff243ee21e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['tokenize_text'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9584a01c-9212-45ff-9c1d-11bc69962cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f52ba350-ec53-4c46-8d76-c1c338b1172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "babea72c-867e-4338-9ed5-25128b28bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stem_text'] = df['filtered_text'].apply(lambda x: [stem.stem(word)for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee1563a7-53a2-4ada-a434-53c50e6d605e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wonder',\n",
       " 'littl',\n",
       " 'product',\n",
       " 'film',\n",
       " 'techniqu',\n",
       " 'unassum',\n",
       " 'oldtimebbc',\n",
       " 'fashion',\n",
       " 'give',\n",
       " 'comfort',\n",
       " 'sometim',\n",
       " 'discomfort',\n",
       " 'sens',\n",
       " 'realism',\n",
       " 'entir',\n",
       " 'piec',\n",
       " 'actor',\n",
       " 'extrem',\n",
       " 'well',\n",
       " 'chosen',\n",
       " 'michael',\n",
       " 'sheen',\n",
       " 'got',\n",
       " 'polari',\n",
       " 'voic',\n",
       " 'pat',\n",
       " 'truli',\n",
       " 'see',\n",
       " 'seamless',\n",
       " 'edit',\n",
       " 'guid',\n",
       " 'refer',\n",
       " 'william',\n",
       " 'diari',\n",
       " 'entri',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'watch',\n",
       " 'terrificli',\n",
       " 'written',\n",
       " 'perform',\n",
       " 'piec',\n",
       " 'master',\n",
       " 'product',\n",
       " 'one',\n",
       " 'great',\n",
       " 'master',\n",
       " 'comedi',\n",
       " 'life',\n",
       " 'realism',\n",
       " 'realli',\n",
       " 'come',\n",
       " 'home',\n",
       " 'littl',\n",
       " 'thing',\n",
       " 'fantasi',\n",
       " 'guard',\n",
       " 'rather',\n",
       " 'use',\n",
       " 'tradit',\n",
       " 'dream',\n",
       " 'techniqu',\n",
       " 'remain',\n",
       " 'solid',\n",
       " 'disappear',\n",
       " 'play',\n",
       " 'knowledg',\n",
       " 'sens',\n",
       " 'particularli',\n",
       " 'scene',\n",
       " 'concern',\n",
       " 'orton',\n",
       " 'halliwel',\n",
       " 'set',\n",
       " 'particularli',\n",
       " 'flat',\n",
       " 'halliwel',\n",
       " 'mural',\n",
       " 'decor',\n",
       " 'everi',\n",
       " 'surfac',\n",
       " 'terribl',\n",
       " 'well',\n",
       " 'done']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stem_text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a832934c-262c-4014-9546-cbe8038cfba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wonderful',\n",
       " 'little',\n",
       " 'production',\n",
       " 'filming',\n",
       " 'technique',\n",
       " 'unassuming',\n",
       " 'oldtimebbc',\n",
       " 'fashion',\n",
       " 'gives',\n",
       " 'comforting',\n",
       " 'sometimes',\n",
       " 'discomforting',\n",
       " 'sense',\n",
       " 'realism',\n",
       " 'entire',\n",
       " 'piece',\n",
       " 'actors',\n",
       " 'extremely',\n",
       " 'well',\n",
       " 'chosen',\n",
       " 'michael',\n",
       " 'sheen',\n",
       " 'got',\n",
       " 'polari',\n",
       " 'voices',\n",
       " 'pat',\n",
       " 'truly',\n",
       " 'see',\n",
       " 'seamless',\n",
       " 'editing',\n",
       " 'guided',\n",
       " 'references',\n",
       " 'williams',\n",
       " 'diary',\n",
       " 'entries',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'watching',\n",
       " 'terrificly',\n",
       " 'written',\n",
       " 'performed',\n",
       " 'piece',\n",
       " 'masterful',\n",
       " 'production',\n",
       " 'one',\n",
       " 'great',\n",
       " 'masters',\n",
       " 'comedy',\n",
       " 'life',\n",
       " 'realism',\n",
       " 'really',\n",
       " 'comes',\n",
       " 'home',\n",
       " 'little',\n",
       " 'things',\n",
       " 'fantasy',\n",
       " 'guard',\n",
       " 'rather',\n",
       " 'use',\n",
       " 'traditional',\n",
       " 'dream',\n",
       " 'techniques',\n",
       " 'remains',\n",
       " 'solid',\n",
       " 'disappears',\n",
       " 'plays',\n",
       " 'knowledge',\n",
       " 'senses',\n",
       " 'particularly',\n",
       " 'scenes',\n",
       " 'concerning',\n",
       " 'orton',\n",
       " 'halliwell',\n",
       " 'sets',\n",
       " 'particularly',\n",
       " 'flat',\n",
       " 'halliwells',\n",
       " 'murals',\n",
       " 'decorating',\n",
       " 'every',\n",
       " 'surface',\n",
       " 'terribly',\n",
       " 'well',\n",
       " 'done']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filtered_text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81b11bdb-5359-4845-8bcb-e33d448d5c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "816e04e5-b48c-46f9-a8f0-b6eb8c081ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "974b826f-8375-40e5-9b79-210446562d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemma_text'] = df['filtered_text'].apply(lambda x: [lemma.lemmatize(word)for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5e3cbaf-8c8c-47a0-bc32-4fa9e8a86787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wonderful',\n",
       " 'little',\n",
       " 'production',\n",
       " 'filming',\n",
       " 'technique',\n",
       " 'unassuming',\n",
       " 'oldtimebbc',\n",
       " 'fashion',\n",
       " 'give',\n",
       " 'comforting',\n",
       " 'sometimes',\n",
       " 'discomforting',\n",
       " 'sense',\n",
       " 'realism',\n",
       " 'entire',\n",
       " 'piece',\n",
       " 'actor',\n",
       " 'extremely',\n",
       " 'well',\n",
       " 'chosen',\n",
       " 'michael',\n",
       " 'sheen',\n",
       " 'got',\n",
       " 'polari',\n",
       " 'voice',\n",
       " 'pat',\n",
       " 'truly',\n",
       " 'see',\n",
       " 'seamless',\n",
       " 'editing',\n",
       " 'guided',\n",
       " 'reference',\n",
       " 'williams',\n",
       " 'diary',\n",
       " 'entry',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'watching',\n",
       " 'terrificly',\n",
       " 'written',\n",
       " 'performed',\n",
       " 'piece',\n",
       " 'masterful',\n",
       " 'production',\n",
       " 'one',\n",
       " 'great',\n",
       " 'master',\n",
       " 'comedy',\n",
       " 'life',\n",
       " 'realism',\n",
       " 'really',\n",
       " 'come',\n",
       " 'home',\n",
       " 'little',\n",
       " 'thing',\n",
       " 'fantasy',\n",
       " 'guard',\n",
       " 'rather',\n",
       " 'use',\n",
       " 'traditional',\n",
       " 'dream',\n",
       " 'technique',\n",
       " 'remains',\n",
       " 'solid',\n",
       " 'disappears',\n",
       " 'play',\n",
       " 'knowledge',\n",
       " 'sens',\n",
       " 'particularly',\n",
       " 'scene',\n",
       " 'concerning',\n",
       " 'orton',\n",
       " 'halliwell',\n",
       " 'set',\n",
       " 'particularly',\n",
       " 'flat',\n",
       " 'halliwells',\n",
       " 'mural',\n",
       " 'decorating',\n",
       " 'every',\n",
       " 'surface',\n",
       " 'terribly',\n",
       " 'well',\n",
       " 'done']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemma_text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39146797-1f91-4055-be1b-8d152de73bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['stem_text']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "622f2348-1bbd-4a73-9100-feedfcf9924f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1        positive\n",
       "2        positive\n",
       "3        negative\n",
       "4        positive\n",
       "           ...   \n",
       "49995    positive\n",
       "49996    negative\n",
       "49997    negative\n",
       "49998    negative\n",
       "49999    negative\n",
       "Name: sentiment, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28461979-6810-45f5-a236-65fd2dd8a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be752757-80fc-4be5-968d-a608334d6637",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_tyrain, y_test = train_test_split(X,y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e5931dd-4b01-40a5-9bf4-7975744de517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39087    [that, kept, ask, mani, fight, scream, match, ...\n",
       "30893    [watch, entir, movi, could, watch, entir, movi...\n",
       "45278    [touch, love, stori, reminisc, mood, love, dra...\n",
       "16398    [latterday, fulci, schlocker, total, abysm, co...\n",
       "13653    [first, firmli, believ, norwegian, movi, conti...\n",
       "                               ...                        \n",
       "11284    [shadow, magic, recaptur, joy, amaz, first, mo...\n",
       "44732    [found, movi, quit, enjoy, fairli, entertain, ...\n",
       "38158    [avoid, one, terribl, movi, excit, pointless, ...\n",
       "860      [product, quit, surpris, absolut, love, obscur...\n",
       "15795    [decent, movi, although, littl, bit, short, ti...\n",
       "Name: stem_text, Length: 40000, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02757208-a54b-486d-9aee-a934213ea0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33553    [realli, like, summerslam, due, look, arena, c...\n",
       "9427     [mani, televis, show, appeal, quit, mani, diff...\n",
       "199      [film, quickli, get, major, chase, scene, ever...\n",
       "12447    [jane, austen, would, definit, approv, onegwyn...\n",
       "39489    [expect, somewhat, high, went, see, movi, thou...\n",
       "                               ...                        \n",
       "28567    [although, casper, van, dien, michael, rooker,...\n",
       "25079    [like, movi, wasnt, realli, sure, start, watch...\n",
       "18707    [ye, nonsingaporean, cant, see, what, big, dea...\n",
       "15200    [far, film, go, likabl, enough, entertain, cha...\n",
       "5857     [saw, anatomi, year, ago, dub, friend, hous, d...\n",
       "Name: stem_text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c96fc764-1497-4616-8388-40e8fbb0bd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39087    negative\n",
       "30893    negative\n",
       "45278    positive\n",
       "16398    negative\n",
       "13653    negative\n",
       "           ...   \n",
       "11284    positive\n",
       "44732    positive\n",
       "38158    negative\n",
       "860      positive\n",
       "15795    positive\n",
       "Name: sentiment, Length: 40000, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tyrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69afef1c-9d83-429a-ba46-75c60070b1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33553    positive\n",
       "9427     positive\n",
       "199      negative\n",
       "12447    positive\n",
       "39489    negative\n",
       "           ...   \n",
       "28567    negative\n",
       "25079    positive\n",
       "18707    positive\n",
       "15200    negative\n",
       "5857     positive\n",
       "Name: sentiment, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "646bee53-b8d8-4591-8c4b-e098d93f609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2744af54-fd83-4479-9004-7e66d25af20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52916e42-8d5c-4b23-aab3-a903d3337f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39087    [that, kept, ask, mani, fight, scream, match, ...\n",
       "30893    [watch, entir, movi, could, watch, entir, movi...\n",
       "45278    [touch, love, stori, reminisc, mood, love, dra...\n",
       "16398    [latterday, fulci, schlocker, total, abysm, co...\n",
       "13653    [first, firmli, believ, norwegian, movi, conti...\n",
       "                               ...                        \n",
       "11284    [shadow, magic, recaptur, joy, amaz, first, mo...\n",
       "44732    [found, movi, quit, enjoy, fairli, entertain, ...\n",
       "38158    [avoid, one, terribl, movi, excit, pointless, ...\n",
       "860      [product, quit, surpris, absolut, love, obscur...\n",
       "15795    [decent, movi, although, littl, bit, short, ti...\n",
       "Name: stem_text, Length: 40000, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7dc010e3-4675-449a-a8f6-d1344db7fe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf.fit_transform(X_train.apply(lambda x:''.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec6ec1a8-e607-457d-91df-07738f7abb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf.transform(X_test.apply(lambda x: \"\".join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8c09e05-3c9e-4d98-bb4e-56e6f3c8c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25bf8930-8e69-4072-a2cb-0d16e00ca5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_tyrain)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81a0fb30-e29f-4d16-9c5f-08aadb3fc8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d3ffb1a-2f18-492a-acad-9d67188377ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65adb573-0fe4-4a6d-9a1c-e0cfb7f49b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d85baa8-1034-4902-afd6-be6c3098a739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 39741)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9ce6328-2b76-49ff-aaa7-04c21ff7e1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61bb57f2-5a43-45d4-8954-7bb3f0a1904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05153d7c-8ba7-4070-94ab-26b670351a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f09c20c5-28ff-4f12-a466-9cb998cc2753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DAIDA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(2, activation=\"sigmoid\")\n",
    "])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4104f1b1-2c5a-4d06-b9c0-a6e3080d7235",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c3c3ef0-8076-482f-b4c2-9b3714534a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 275ms/step - accuracy: 0.5035 - loss: 0.6932\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 206ms/step - accuracy: 0.9014 - loss: 0.2162\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.3964e-06\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 1.2277e-06\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.1399e-06\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.0209e-06\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 8.9473e-07\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 7.3026e-07\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 5.5781e-07\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.8906e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1520405fc20>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be39b5a4-b91b-43b6-8d61-1e247d66dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Assuming your trained model is named 'model'\n",
    "joblib.dump(model, 'model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf.pkl')\n",
    "\n",
    "# Load the model and TF-IDF vectorizer\n",
    "model = joblib.load('model.pkl')\n",
    "tf_idf_vector = joblib.load('model.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize NLTK tools\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to predict sentiment\n",
    "def predict_sentiment(review):\n",
    "    cleaned_review = re.sub('<.*?>', '', review)\n",
    "    cleaned_review = re.sub(r'[^\\w\\s]', '', cleaned_review)\n",
    "    cleaned_review = cleaned_review.lower()\n",
    "    tokenized_review = word_tokenize(cleaned_review)\n",
    "    filtered_review = [word for word in tokenized_review if word not in stop_words]\n",
    "    stemmed_review = [stemmer.stem(word) for word in filtered_review]\n",
    "    tfidf_review = tf_idf_vector.transform([' '.join(stemmed_review)])\n",
    "    sentiment_prediction = model.predict(tfidf_review)\n",
    "    if sentiment_prediction > 0.6:  # Adjust threshold as needed\n",
    "        return \"Positive\"\n",
    "        \n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "# Streamlit UI\n",
    "st.title('Sentiment Analysis')\n",
    "review_to_predict = st.text_area('Enter your review here:')\n",
    "if st.button('Predict Sentiment'):\n",
    "    predicted_sentiment = predict_sentiment(review_to_predict)\n",
    "    st.write(\"Predicted Sentiment:\", predicted_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31e1d9f9-8574-4d95-8175-a9dc1938a4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
      "Try 'streamlit run --help' for help.\n",
      "\n",
      "Error: Streamlit requires raw Python (.py) files, not .ipynb.\n",
      "For more information, please see https://docs.streamlit.io\n"
     ]
    }
   ],
   "source": [
    "!streamlit run NLP.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e7de16d-f1f5-48b1-843c-929346f69434",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ipynb-py-convert NLP.ipynb NLP.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ea8f319-041e-4280-a1f1-e84a706da65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipynb-py-convert in c:\\users\\daida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ipynb-py-convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef760a4f-3441-47da-b257-3fbe7f601036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34dcb4-7f71-4213-8b11-b097f01fc795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
